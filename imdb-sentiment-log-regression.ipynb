{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanna\\Anaconda3\\envs\\421-c\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import string\n",
    "from scipy import spatial\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gets positive and negative review folders\n",
    "base_data_dir = \"..\" + os.sep + \"txt_sentoken\"\n",
    "pos_files = base_data_dir + os.sep + 'pos'\n",
    "neg_files = base_data_dir + os.sep + 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files(directory, label):\n",
    "    reviews = []\n",
    "    for filename in os.listdir(directory):\n",
    "        file = directory + os.sep + filename\n",
    "        with smart_open.smart_open(file, encoding=\"iso-8859-1\") as f:\n",
    "            review = bytearray()\n",
    "            for i, line in enumerate(f):\n",
    "                review += line\n",
    "            reviews.append({\"review\": review, \"label\": label})\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts files\n",
    "pos_reviews = get_files(pos_files, 1)\n",
    "neg_reviews = get_files(neg_files, 0)\n",
    "p = list(pos_reviews)\n",
    "n = list(neg_reviews)\n",
    "random.shuffle(p)\n",
    "random.shuffle(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(filename, tokens_only=False):\n",
    "    with smart_open.smart_open(filename, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(docs):\n",
    "    test = []\n",
    "    train = []\n",
    "    labels = {}\n",
    "    count = 2\n",
    "    for i, doc_set in enumerate(docs):\n",
    "        for j, doc in enumerate(doc_set):\n",
    "            if j < len(doc_set) / 2:\n",
    "                test.append({\"doc\": gensim.utils.simple_preprocess(doc_set[j][\"review\"]), \"label\": doc_set[j][\"label\"]})\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                res = gensim.models.doc2vec.TaggedDocument(\n",
    "                    gensim.utils.simple_preprocess(doc_set[j][\"review\"]), [count, doc_set[j][\"label\"]])\n",
    "                if doc_set[j][\"label\"] in labels:\n",
    "                    labels[doc_set[j][\"label\"]].append(count)\n",
    "                else:\n",
    "                    labels[doc_set[j][\"label\"]] = [count]\n",
    "                count += 1\n",
    "                train.append(res)\n",
    "    return test, train, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus, train_corpus, train_labels = test_train_split([p, n])\n",
    "random.shuffle(train_corpus)\n",
    "# print(train_corpus)\n",
    "# print(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(size=100, min_count=5, iter=100, dm=0, dbow_words=1, window=5) \n",
    "# size is vector size\n",
    "# min_count is the number of times a word needs to be used\n",
    "#iter is number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gets vocab\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46407726"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trains model on texts\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bad', 0.6571986675262451),\n",
       " ('but', 0.6016497611999512),\n",
       " ('pretty', 0.5924533009529114),\n",
       " ('really', 0.5748573541641235),\n",
       " ('decent', 0.5742709636688232),\n",
       " ('very', 0.5679540634155273),\n",
       " ('great', 0.5480868816375732),\n",
       " ('potent', 0.5196850895881653),\n",
       " ('still', 0.5169124603271484),\n",
       " ('amazing', 0.5094337463378906)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('casted', 0.4692346453666687),\n",
       " ('shelved', 0.45204877853393555),\n",
       " ('wire', 0.4443809688091278),\n",
       " ('bad', 0.4373916983604431),\n",
       " ('previously', 0.42407336831092834),\n",
       " ('made', 0.40651363134384155),\n",
       " ('rosanna', 0.40070217847824097),\n",
       " ('frustrating', 0.40007495880126953),\n",
       " ('encountered', 0.40002942085266113),\n",
       " ('originally', 0.3927207291126251)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('films', 0.5964456796646118),\n",
       " ('genre', 0.575140655040741),\n",
       " ('thriller', 0.5289715528488159),\n",
       " ('slasher', 0.5172624588012695),\n",
       " ('movies', 0.5072332620620728),\n",
       " ('flicks', 0.505022406578064),\n",
       " ('film', 0.5042519569396973),\n",
       " ('rocky', 0.5004055500030518),\n",
       " ('fi', 0.4986109435558319),\n",
       " ('flick', 0.49328815937042236)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"horror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assess model\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counts what ranks each document was classified as\n",
    "# collections.Counter(ranks)  # Results vary due to random seeding and very small corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_corpus[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "x = [model.infer_vector(d[0]) for d in train_corpus]\n",
    "y = [d[1][1] for d in train_corpus]\n",
    "classifier.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84699999999999998"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score([model.infer_vector(d['doc']) for d in test_corpus], [d['label'] for d in test_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./imdb-log.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "421-c",
   "language": "python",
   "name": "421-c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
