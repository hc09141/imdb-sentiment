{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanna\\Anaconda3\\envs\\421-c\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import string\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gets positive and negative review folders\n",
    "base_data_dir = \"txt_sentoken\"\n",
    "pos_files = base_data_dir + os.sep + 'pos'\n",
    "neg_files = base_data_dir + os.sep + 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files(directory):\n",
    "    reviews = []\n",
    "    for filename in os.listdir(directory):\n",
    "        file = directory + os.sep + filename\n",
    "        with smart_open.smart_open(file, encoding=\"iso-8859-1\") as f:\n",
    "            review = bytearray()\n",
    "            for i, line in enumerate(f):\n",
    "                review += line\n",
    "#             print(review)\n",
    "#             return\n",
    "            reviews.append(review)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converts files\n",
    "pos_reviews = get_files(pos_files)\n",
    "neg_reviews = get_files(neg_files)\n",
    "random.shuffle(pos_reviews)\n",
    "random.shuffle(neg_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(filename, tokens_only=False):\n",
    "    with smart_open.smart_open(filename, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_train_split(docs, labels):\n",
    "    test = []\n",
    "    train = []\n",
    "    count = 0\n",
    "    for i, doc_set in enumerate(docs):\n",
    "        for j, doc in enumerate(doc_set):\n",
    "            if j < len(doc_set) / 2:\n",
    "                test.append({\"doc\": gensim.utils.simple_preprocess(doc_set[j]), \"label\": labels[i]})\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                res = gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(doc_set[j]), [count, labels[i]])\n",
    "                count += 1\n",
    "                train.append(res)\n",
    "    return test, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus, train_corpus = test_train_split([pos_reviews, neg_reviews], [\"pos\", \"neg\"])\n",
    "random.shuffle(train_corpus)\n",
    "random.shuffle(test_corpus)\n",
    "# print(train_corpus)\n",
    "# print(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(size=100, min_count=10, iter=200) \n",
    "# size is vector size\n",
    "# min_count is the number of times a word needs to be used\n",
    "#iter is number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gets vocab\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84975058"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trains model on texts\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assess model\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counts what ranks each document was classified as\n",
    "# collections.Counter(ranks)  # Results vary due to random seeding and very small corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "pos_vec = model.docvecs['pos']\n",
    "neg_vec = model.docvecs['neg']\n",
    "for doc in test_corpus:\n",
    "    inferred_vector = model.infer_vector(doc[\"doc\"])\n",
    "    pos_dist = spatial.distance.cosine(inferred_vector, pos_vec)\n",
    "    neg_dist = spatial.distance.cosine(inferred_vector, neg_vec)\n",
    "    if pos_dist < neg_dist and doc[\"label\"] == \"pos\":        \n",
    "        correct += 1\n",
    "    elif neg_dist < pos_dist and doc[\"label\"] == \"neg\":\n",
    "        correct += 1\n",
    "print(correct / len(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./imdb.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "421-c",
   "language": "python",
   "name": "421-c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
